#############################################################
# Τα δεδομένα και οι παράμετροι της εκ των προτέρων κατανομής

x = c(4, 5, 4, 1, 0, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3, 
1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 
1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 
0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2, 
1, 1, 1, 1, 2, 4, 2, 0, 0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 
1, 0, 0, 1, 0, 1)

n = length(x)

g1=d1=g2=d2=0.01

# Για να δείτε τα δεδομένα:

plot(x)

# Συνήθως τις παρατηρηθείσες χρονοσειρές τις σχεδιάζουμε 
# ενώνοντας τις τιμές με μία γραμμή:

plot(x,type="l")


###############################################
# pk: Το διάνυσμα των εκ των υστέρων πιθανοτήτων π(k|x)
# Είδαμε ότι παρ' όλο που θεωρητικά αυτή η μέθοδος είναι 
# σωστή, στην πράξη δεν δουλεύει λόγω των μεγάλων τιμών 

pk = rep(NaN,n-1)

for( k in 1:(n-1) ){
	pk[k] = ( gamma(g1+sum(x[1:k]))*gamma(g2+sum(x[(k+1):n])) )/
		( (d1+k)^(g1+sum(x[1:k]))*(d2+n-k)^(g2+sum(x[(k+1):n])) )
	}

pk = pk/sum(pk)


###############################################
# Εδώ υπολογίζονται οι πιθανότητες ξεκινώντας από τους 
# λογαρίθμους τους. pk είναι οι πιθανότητες (αυτές
# που στην τάξη τις είχαμε pk.new

logpk = rep(NaN,n-1)

for( k in 1:(n-1) ){
	logpk[k] = lgamma(g1+sum(x[1:k]))+lgamma(g2+sum(x[(k+1):n]))- 
		(g1+sum(x[1:k]))*log(d1+k)-(g2+sum(x[(k+1):n]))*log(d2+n-k)
	}

pk = exp(logpk)/sum(exp(logpk))

####################################################
# Για να δείτε γραφικά την π(k|x):

plot(pk,type="h")


#################################################
# kmode είναι το k με τη μέγιστη πιθανότητα π(k|x)

kmode = which(pk==max(pk),arr.ind=T)

#################################################
# kset ξεκινάει έχοντας την τιμή kmode και στη συνέχεια
# "γεμίζει" με τις πλησιέστερες τιμές k έτσι ώστε 
# φτιάξουμε ένα σύνολο τιμών k που όλες μαζί έχουν 
# πιθανότητα (=pkset) τουλάχιστον 95% 

kset = which(pk==max(pk),arr.ind=T) # ( =kmode )
pkset = max(pk)

k.up = kset+1; k.down = kset-1
while ( pkset<0.95 ){
	if ( pk[k.up]>pk[k.down] ){
		kset = c(kset,k.up); pkset = pkset+pk[k.up]; k.up=k.up+1
		} else {
		kset = c(kset,k.down); pkset = pkset+pk[k.down]; k.down=k.down-1
		}
	}
kset = sort(kset)

# Αυτό το while δουλεύει ως εξής: Όταν φτάνουμε εκεί, 
# το pkset έχει την τιμή max(pk) (είναι περίπου 0.242). 
# Αν το αμέσως επόμενο k από τον kmode έχει μεγαλύτερη 
# πιθανότητα από το αμέσως προηγούμενο, (αν pk[k.up]>pk[k.down])
# τότε βάζει στο σύνολο kset το k.up αλλιώς βάζει το k.down.
# Στη συνέχεια αυξάνει την πιθανότητα του συνόλου kset προσθέτοντας
# στο pkset την πιθανότητα του k που πρόσθεσε στο σύνολο (δηλ. είτε
# του k.up είτε του k.down) και "μετακινεί" το k.up ή το k.down κατά
# ένα. Αυτό συνεχίζεται μέχρι η συνολική εκ των υστέρων πιθανότητα
# του συνόλου kset να ξεπεράσει το 0.95. Στο τέλος το σύνολο kset
# διατάσσεται από την μικρότερη στη μεγαλύτερη τιμή.

##########################################################################
# Εδώ υπολογίζουμε ένα άλλο 95% αξιόπιστο σύνολο όπως
# πρότεινε στην τάξη ο Γιάννης: Είπε να πάρουμε τα k με 
# τις μεγαλύτερες εκ των υστέρων πιθανότητες, δηλαδή να βρούμε 
# το 95% σύνολο υψίστης εκ των υστέρων πυκνότητας.
# Στην τάξη έκανα τα εξής: Πρώτα έφτιαξα το

sums.of.pk = cumsum(rev(sort(pk)))

# sort(pk) διατάσσει τις πιθανότητες από την μικρότερη στη μεγαλύτερη, 
# rev(sort(pk)) αντιστρέφει τη σειρά στο προηγούμενο διάνυσμα, δηλαδή
# περιέχει τις πιθανότητες διατεταγμένες από την μεγαλύτερη στη μικρότερη, 
# cumsum(rev(sort(pk))) έχει τα μερικά αθροίσματα, δηλαδή πρώτα 
# την μέγιστη, μετά το άθροισμα των δύο μεγαλύτερων, μετά των τριών κ.ο.κ.

min( (1:(n-1))[sums.of.pk>0.95] )

# δίνει τον δείκτη στα μερικά αθροίσματα που πρωτοξεπερνάει το 0.95:
# (1:(n-1))[sums.of.pk>0.95] είναι οι δείκτες από το 1 έως το n-1 που 
# αντιστοιχούν σε μερικά αθροίσματα πάνω από 0.95, και το min (=minimum)
# αυτών είναι ο πρώτος δείκτης που το ξεπερνά.

rev(order(pk))

# Το διάνυσμα order(pk) περιέχει τους δείκτες που αντιστοιχούν στο 
# sort(pk): Το sort(pk) είναι το διάνυσμα των διατεταγμένων τιμών pk
# και το order(pk) οι αντίστοιχοι δείκτες τους στο pk. 
# Το rev(order(pk)) είναι οι δείκτες που αντιστοιχούν στο ref(sort(pk)).
# (Το rev(order(pk)) έχει πρώτη πρώτη τιμή το kmode.)

# Το 95% αξιόπιστο σύνολο υψίστης εκ των υστέρων πυκνότητας είναι το

kset.HPD = sort( rev(order(pk))[1:min((1:(n-1))[sums.of.pk>0.95])] )

# δηλαδή παίρνουμε από το rev(order(pk)) τους min((1:(n-1))[sums.of.pk>0.95])
# πρώτους δείκτες και (για σύγκριση το kset που βρήκαμε προηγουμένως) τους
# διατάσσουμε. (HPD=high posterior density)
# Παρατηρήστε ότι το kset.HPD περιέχει λιγότερους δείκτες από το kset. 
# Αυτό είναι φυσικό μια και αυτό το σύνολο δεν ενδιαφέρεται να περιέχει 
# "συνεχόμενους" δείκτες αλλά τους πιο πιθανούς και επομένως φτάνει το 
# 0.95 πιο γρήγορα. 

# Στην τάξη ο Νίκος που καθόταν πίσω πίσω πρότεινε για το ίδιο σύνολο 
# να κάνω μία "ανάποδη" διαδικασία. (Ίσως είναι περισσότερο ορθόδοξη
# από αυτήν που έκανα εγώ.) 

sums2.of.pk = cumsum(sort(pk))
kset2.HPD = sort( order(pk)[(max((1:(n-1))[sums2.of.pk<=0.05])+1):(n-1)] )

# Το kset2.HPD είναι το ίδιο με το kset.HPD. Το γιατί δικό σας (πάμε! :p )


########################################################################
# Εδώ προσομοιώνουμε 10000 τιμές από την π(λ1|x). 
# Γενικά έτσι προσομοιώνουμε από μείξεις: Στην πραγματικότητα
# προσομοιώνουμε από την από κοινού των k,λ1 και κρατάμε τις τιμές των λ1

lambda1=c()
for ( j in 1:10000 ){
	k = sample(1:(n-1),prob=pk,size=1)
	lambda1 = c(lambda1,rgamma(1,shape=g1+sum(x[1:k]),rate=d1+k))
	}

# Αρχικά, lambda1 είναι μία κενή λίστα (διάνυσμα) που θα γεμίσει
# βήμα βήμα (για j από 1 έως 10000) με τις προσομοιωμένες τιμές λ1. 
# Σε κάθε βήμα γίνονται τα εξής:
# Πρώτα γεννάμε ένα k~π(k|x): Παίρνουμε μία τιμή k (μία μόνο, το λέει το
# "size=1") από το 1 έως το n-1 (γι' αυτό έχει το 1:(n-1) ) 
# με πιθανότητα pk[k] (prob=pk). Μετά, χρησιμοποιώντας αυτήν την τιμή, 
# γεννάμε ένα lambda από την γάμμα με παράμετρο σχήματος g1+sum(x[1:k])
# και ρυθμού d1+k, δηλαδή από την εκ των υστέρων του λ1 δοθέντος k.
# Η τιμή που προσομοιώθηκε μπαίνει στο τέλος της λίστας των προσομοιωμένων
# λ1.  
# Αν θέλαμε και από την π(λ2|x) θα τρέχαμε αυτό:

lambda1=c(); lambda2=c()
for ( j in 1:10000 ){
	k = sample(1:(n-1),prob=pk,size=1)
	lambda1 = c(lambda1,rgamma(1,shape=g1+sum(x[1:k]),rate=d1+k))
	lambda2 = c(lambda2,rgamma(1,shape=g2+sum(x[(k+1):n]),rate=d2+n-k))
	}

# Ιστόγραμμα των προσομοιωμένων τιμών λ1: Εκτιμά την π(λ1|x)

hist(lambda1,freq=F)

# Αντίστοιχα, για την λ2:

hist(lambda2,freq=F)


# Εκτιμήσεις (προσεγγίσεις από την προσομοίωση) των εκ των υστέρων 
# μέσων τιμών E(λ1|x), Ε(λ2|x)

c( mean(lambda1),mean(lambda2) )

# και των εκ των υστέρων διαμέσων

c( median(lambda1),median(lambda2) )

# Προσεγγίσεις των 90% αξιόπιστων διαστημάτων ίσων ουρών:

int.lambda1 = c(quantile(lambda1,0.05),quantile(lambda1,0.95)) 

int.lambda2 = c(quantile(lambda2,0.05),quantile(lambda2,0.95)) 

# Αν δεν σας αρέσει να βλέπετε τα "5%" και "95%" πάνω από τα όρια
# γράψτε names(int.lambda1)=c()



















